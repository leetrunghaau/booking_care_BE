const createError = require("http-errors");
const aiConfig = require("../../../config/ai-config");

class AI {
    static async chat(req, res, next) {
        try {
            let message = req.body?.message;

            // Step 1: G·ªçi ƒë·∫øn RAG API ƒë·ªÉ l·∫•y t√†i li·ªáu li√™n quan
            const ragResponse = await fetch(`${aiConfig.search_URL}/search`, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ query: message }),
            });

            const ragData = await ragResponse.json();
            let contextText = "";

            if (ragData.found && Array.isArray(ragData.results)) {
                contextText = ragData.results.map(r => r.text).join("\n---\n");
                console.log("üìö RAG t√¨m th·∫•y context:", contextText.slice(0, 200), "...");
            } else {
                console.log("‚õÖ Kh√¥ng t√¨m th·∫•y t√†i li·ªáu t·ª´ RAG. Tr·∫£ v·ªÅ ph·∫£n h·ªìi ƒë∆°n gi·∫£n.");

                res.setHeader("Content-Type", "text/event-stream");
                res.setHeader("Cache-Control", "no-cache");
                res.setHeader("Connection", "keep-alive");

                const fullMessage =
                    "ü©∫ Xin ch√†o b·∫°n,\n" +
                    "Hi·ªán t·∫°i m√¨nh ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p cho c√¢u h·ªèi c·ªßa b·∫°n.\n" +
                    "üìç Vui l√≤ng th·ª≠ l·∫°i v·ªõi c√¢u h·ªèi c·ª• th·ªÉ h∆°n.\n" +
                    "‚òéÔ∏è C·∫ßn h·ªó tr·ª£ nhanh? G·ªçi 0367 016 872.\n" +
                    "üíô C·∫£m ∆°n b·∫°n ƒë√£ tin t∆∞·ªüng MedPlus!";

                (async () => {
                    for (const char of fullMessage) {
                        res.write(char);
                        await new Promise(resolve => setTimeout(resolve, 30)); // Delay m·ªói k√Ω t·ª±
                    }
                    res.end();
                })();
                return;
                
            }

            // Step 2: G·ª≠i t·ªõi Ollama k√®m context
            const ollamaRequestBody = {
                model: "medly:latest",
                stream: true,
                messages: [],
            };

            message = `D∆∞·ªõi ƒë√¢y l√† t√†i li·ªáu tham kh·∫£o:\n${contextText}\n\nVui l√≤ng tr·∫£ l·ªùi th·∫≠t ng·∫Øn g·ªçn, t·ªëi ƒëa 3 c√¢u. C√¢u h·ªèi c·ªßa sau: ${message}`;

            ollamaRequestBody.messages.push({
                role: "user",
                content: message
            });

            const response = await fetch(`${aiConfig.medly_URL}/api/chat`, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify(ollamaRequestBody),
            });

            // Step 3: Stream response t·ª´ Ollama v·ªÅ frontend
            res.setHeader("Content-Type", "text/event-stream");
            res.setHeader("Cache-Control", "no-cache");
            res.setHeader("Connection", "keep-alive");

            const reader = response.body.getReader();
            const decoder = new TextDecoder();

            while (true) {
                const { done, value } = await reader.read();
                if (done) {
                    console.log("‚úÖ K·∫øt th√∫c ƒë·ªçc stream t·ª´ AI.");
                    res.end();
                    break;
                }
                const chunk = decoder.decode(value, { stream: true });

                try {
                    const chunkOBJ = JSON.parse(chunk);
                    res.write(`${chunkOBJ.message?.content || ""}`);
                } catch (e) {
                    console.error("‚ùå L·ªói parse chunk:", chunk);
                }
            }
        } catch (error) {
            console.error("‚ùå L·ªói t·ªïng th·ªÉ:", error);
            return next(createError.InternalServerError());
        }
    }
}

module.exports = AI;
